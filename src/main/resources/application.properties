# The follow control the ganglia server being used
ganglia.port=${ganglia.port}
ganglia.server=${ganglia.server}

# Controls the HBase table being used
density-cube.cubeTable=${density-cube.table}

# The following can remain hard coded, but were designed to be configurable for future proofing
density-cube.columnFamily=dc
tile-server.cube.harness=hbase
density-cube.writeBatchSize=1000


occurrence.db.table_name=${occurrence.db.table_name}
occurrence.db.counter_table_name=${occurrence.db.counter_table_name}
occurrence.db.max_connection_pool=${occurrence.db.max_connection_pool}
occurrence.db.id_lookup_table_name=${occurrence.db.id_lookup_table_name}
occurrence.db.zookeeper.connection_string=${occurrence.db.zookeeper.connection_string}

occurrence.search.solr.server=${occurrence.search.solr.server}
occurrence.search.solr.server.type=${occurrence.search.solr.server.type}
occurrence.search.solr.server.httpLbservers=
occurrence.search.solr.embedded=false
occurrence.search.solr.request_handler=
occurrence.search.solr.collection=${occurrence.search.solr.collection}
occurrence.search.max.offset=200000
occurrence.search.max.limit=300

checklistbank.ws.url=${checklistbank.ws.url}
checklistbank.match.ws.url=${checklistbank.match.ws.url}



# Expert use only: the following can be used during development of tile renderers
# "csv-in-memory" or "hbase" depending on the storage layer
# "csv-in-memory" is for a single csv file of lat,lng,count that
# creates a single dimension taxon cube using key "1" and is intented for offline development
# purposes
#tile-server.cube.harness=csv-in-memory
# A single csv is loaded into an in-memory cube, processed to number of zooms (1-23)
#tile-server.csv.location=/tmp/us-sampled.csv.gz
#tile-server.csv.location=/tmp/us-all.csv.gz
# higher zooms on large files can be slow to start, and use more memory
#tile-server.csv.numberOfZooms=4
#tile-server.csv.pixelsPerCluster=1
